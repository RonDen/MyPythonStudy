{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader(object):\n",
    "    def __init__(self, path, count):\n",
    "        # count: the sample number \n",
    "        self.path = path\n",
    "        self.count = count\n",
    "    def get_file_content(self):\n",
    "        f = open(self.path, 'rb')\n",
    "        content = f.read()   # 读取字节流\n",
    "        f.close()\n",
    "        return content   # 放回字节数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageLoader(Loader):\n",
    "    # 从文件数组中获取第index个图片数据\n",
    "    def get_picture(self, content, index):\n",
    "        start = index*28*28 + 16  # 文件头16个字节，后面每28*28个字节跟一个图片数据\n",
    "        picture = []\n",
    "        for i in range(28):\n",
    "            picture.append([])\n",
    "            for j in range(28):\n",
    "                byte = content[start + i*28 + j]\n",
    "                picture[i].append(byte)\n",
    "        return picture\n",
    "    # 获取一个图像数据sample，这里需要将图片转换成为784行向量的形式\n",
    "    def get_one_sample(self, picture):\n",
    "        sample = []\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                sample.append(picture[i][j])\n",
    "        return sample\n",
    "    # 加载数据文件，获取全部样本向量。onerow来表示是否转化成为一行向量\n",
    "    def load(self, onerow = False):\n",
    "        content = self.get_file_content()\n",
    "        data_set = []\n",
    "        for index in range(self.count):\n",
    "            onepic = self.get_picture(content, index)\n",
    "            if onerow : onepic = self.get_one_sample(onepic)\n",
    "            data_set.append(onepic)\n",
    "        return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据标签加载器\n",
    "class LabelLoader(Loader):\n",
    "    def load(self):\n",
    "        content = self.get_file_content()\n",
    "        labels = []\n",
    "        for index in range(self.count):\n",
    "            onelable = content[index + 8] # 文件头有8个字节\n",
    "            onelablevec = self.norm(onelable)\n",
    "            labels.append(onelablevec)\n",
    "        return labels\n",
    "    def norm(self, label):\n",
    "        label_vec = []\n",
    "        for i in range(10):\n",
    "            if i == label:\n",
    "                label_vec.append(0.9)\n",
    "            else:\n",
    "                label_vec.append(0.1)\n",
    "        return label_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取训练数据集, onerow表示是否转化为行向量\n",
    "def get_training_data_set(num, onerow = False):\n",
    "    image_loader = ImageLoader(\"train-images.idx3-ubyte\", num)\n",
    "    label_loader = LabelLoader(\"train-labels.idx1-ubyte\", num)\n",
    "    return image_loader.load(onerow), label_loader.load()\n",
    "def get_test_data_set(num, onerow = False):\n",
    "    image_loader = ImageLoader(\"t10k-images.idx3-ubyte\", num)\n",
    "    label_loader = LabelLoader(\"t10k-labels.idx1-ubyte\", num)\n",
    "    return image_loader.load(onerow), label_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数，将784行向量打印出来\n",
    "def printImg(onepic):\n",
    "    onepic = onepic.reshape(28, 28)\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            if onepic[i][j] == 0 :\n",
    "                print(\" \", end = '')\n",
    "            else :\n",
    "                print(\"*\", end = '')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "            ************    \n",
      "        ****************    \n",
      "       ****************     \n",
      "       ***********          \n",
      "        ******* **          \n",
      "         *****              \n",
      "           ****             \n",
      "           ****             \n",
      "            ******          \n",
      "             ******         \n",
      "              ******        \n",
      "               *****        \n",
      "                 ****       \n",
      "              *******       \n",
      "            ********        \n",
      "          *********         \n",
      "        **********          \n",
      "      **********            \n",
      "    **********              \n",
      "    ********                \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "5\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "               *****        \n",
      "              ******        \n",
      "             *********      \n",
      "           ***********      \n",
      "           ***********      \n",
      "          ************      \n",
      "         *********  ***     \n",
      "        ******      ***     \n",
      "       *******      ***     \n",
      "       ****         ***     \n",
      "       ***          ***     \n",
      "      ****          ***     \n",
      "      ****        *****     \n",
      "      ***        *****      \n",
      "      ***       ****        \n",
      "      ***      ****         \n",
      "      *************         \n",
      "      ***********           \n",
      "      *********             \n",
      "       *******              \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "0\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                    ***     \n",
      "    **              ***     \n",
      "    **             ****     \n",
      "    **             ***      \n",
      "    **             ***      \n",
      "   ***             ***      \n",
      "   ***            ****      \n",
      "   ***            ****      \n",
      "   ***         ******       \n",
      "   ***   ************       \n",
      "   *****************        \n",
      "    ********     ***        \n",
      "                 ***        \n",
      "                 ***        \n",
      "                 ***        \n",
      "                 ***        \n",
      "                 ***        \n",
      "                 ***        \n",
      "                 ***        \n",
      "                 ***        \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "4\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                  ****      \n",
      "                 *****      \n",
      "                 *****      \n",
      "                ******      \n",
      "               *****        \n",
      "               ****         \n",
      "              *****         \n",
      "             *****          \n",
      "             *****          \n",
      "            *****           \n",
      "           *****            \n",
      "           *****            \n",
      "          *****             \n",
      "          *****             \n",
      "          ****              \n",
      "         *****              \n",
      "        ******              \n",
      "        ****                \n",
      "        ****                \n",
      "        ****                \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "1\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "            *********       \n",
      "           **********       \n",
      "         ************       \n",
      "         *****  *****       \n",
      "        *****   ****        \n",
      "       *****  *****         \n",
      "      ****   ******         \n",
      "      ************          \n",
      "      ***********           \n",
      "       **********           \n",
      "             ****           \n",
      "             ****           \n",
      "              ***           \n",
      "             ****           \n",
      "             ****           \n",
      "             ****           \n",
      "              ***           \n",
      "              ****          \n",
      "              *****         \n",
      "               ****         \n",
      "                            \n",
      "9\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "               *****        \n",
      "             *******        \n",
      "           **********       \n",
      "         ************       \n",
      "         ******* ****       \n",
      "         ******  ****       \n",
      "         ****    ****       \n",
      "                 ****       \n",
      "             ********       \n",
      "          **********        \n",
      "        *************       \n",
      "       ****** ********      \n",
      "      ****** ************   \n",
      "     ****** ***** *******   \n",
      "     ***********     ****   \n",
      "     **********             \n",
      "     *********              \n",
      "     ******                 \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "2\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "            ****            \n",
      "           *****            \n",
      "           *****            \n",
      "            ****            \n",
      "           *****            \n",
      "           ******           \n",
      "            *****           \n",
      "             ****           \n",
      "             ****           \n",
      "             ****           \n",
      "             ****           \n",
      "             ****           \n",
      "             ****           \n",
      "             *****          \n",
      "             *****          \n",
      "             *****          \n",
      "              *****         \n",
      "              *****         \n",
      "              *****         \n",
      "              *****         \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "1\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "           ***********      \n",
      "         **************     \n",
      "         **************     \n",
      "         **************     \n",
      "         ****    ******     \n",
      "                 *****      \n",
      "                ******      \n",
      "              ********      \n",
      "         ************       \n",
      "        ***********         \n",
      "        ************        \n",
      "         ***********        \n",
      "                ****        \n",
      "                ****        \n",
      "      ***      *****        \n",
      "     ****    *******        \n",
      "     **************         \n",
      "     *************          \n",
      "     ***********            \n",
      "      *******               \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "3\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "            ***             \n",
      "            ****            \n",
      "            ****            \n",
      "            ****            \n",
      "            ****            \n",
      "            ****            \n",
      "            ****            \n",
      "             ***            \n",
      "             ***            \n",
      "             ***            \n",
      "             ***            \n",
      "             ***            \n",
      "             ****           \n",
      "             ****           \n",
      "              ***           \n",
      "              ***           \n",
      "              ***           \n",
      "              ***           \n",
      "              ***           \n",
      "              ***           \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "1\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                      **    \n",
      "                     ***    \n",
      "                    ****    \n",
      "                    ***     \n",
      "            ***    ****     \n",
      "            ***    ***      \n",
      "            ***   ****      \n",
      "           ****  *****      \n",
      "          ****   ***        \n",
      "         ****   ****        \n",
      "       ************         \n",
      "       ***********          \n",
      "      **************        \n",
      "      ***   *******         \n",
      "      **    *******         \n",
      "           ****             \n",
      "           ****             \n",
      "          ****              \n",
      "          ***               \n",
      "          ***               \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_data_set, train_data_label = get_training_data_set(100)\n",
    "    train_data_set = np.array(train_data_set)\n",
    "    train_data_labels = np.array(train_data_label)\n",
    "    for i in range(10):\n",
    "        onepic = train_data_set[i]\n",
    "        printImg(onepic)\n",
    "        print(train_data_labels[i].argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立全连接网络模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 当为array的时候，默认d*f就是对应元素的乘积，multiply也是对应元素的乘积，dot（d,f）会转化为矩阵的乘积， dot点乘意味着相加，而multiply只是对应元素相乘，不相加\n",
    "# 2. 当为mat的时候，默认d*f就是矩阵的乘积，multiply转化为对应元素的乘积，dot（d,f）为矩阵的乘积\n",
    "\n",
    "# Sigmoid激活函数类\n",
    "class SigmoidActivator(object):\n",
    "    def forward(self, weighted_input): #前向传播计算输出\n",
    "        try:\n",
    "            result =  1.0 / (1.0 + np.exp(-weighted_input))    \n",
    "        except RuntimeWarning as identifier:\n",
    "            print(weighted_input)\n",
    "        return result\n",
    "        \n",
    "    def backward(self, output):  #后向传播计算导数\n",
    "        return np.multiply(output,(1 - output))   # 对应元素相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全连接每层的实现类。输入对象x、神经层输出a、输出y均为列向量\n",
    "class FullConnectedLayer(object):\n",
    "    # 构造函数。input_size: 本层输入向量的维度。output_size: 本层输出向量的维度。activator: 激活函数\n",
    "    def __init__(self, input_size, output_size,activator):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.activator = activator\n",
    "        # 权重数组W\n",
    "        self.W = np.random.uniform(-0.1, 0.1,(output_size, input_size))  #初始化为-0.1~0.1之间的数。权重的大小。行数=输出个数，列数=输入个数。a=w*x，a和x都是列向量\n",
    "        # 偏置项b\n",
    "        self.b = np.zeros((output_size, 1))  # 全0列向量偏重项\n",
    "        # 输出向量\n",
    "        self.output = np.zeros((output_size, 1)) #初始化为全0列向量\n",
    "    # 前向计算，预测输出。input_array: 输入向量，维度必须等于input_size\n",
    "    def forward(self, input_array):   # 式2\n",
    "        self.input = input_array\n",
    "        self.output = self.activator.forward(np.dot(self.W, input_array) + self.b)\n",
    "\n",
    "    # 反向计算W和b的梯度。delta_array: 从上一层传递过来的误差项。列向量\n",
    "    def backward(self, delta_array):\n",
    "        # 式8\n",
    "        self.delta = np.multiply(self.activator.backward(self.input),np.dot(self.W.T, delta_array))   #计算当前层的误差，已被上一层使用\n",
    "        self.W_grad = np.dot(delta_array, self.input.T)   # 计算w的梯度。梯度=误差.*输入\n",
    "        self.b_grad = delta_array  #计算b的梯度\n",
    "\n",
    "    # 使用梯度下降算法更新权重\n",
    "    def update(self, learning_rate):\n",
    "        self.W += learning_rate * self.W_grad\n",
    "        self.b += learning_rate * self.b_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络类\n",
    "class Network(object):\n",
    "    # 初始化一个全连接神经网络。layers:数组，描述神经网络每层节点数。包含输入层节点个数、隐藏层节点个数、输出层节点个数\n",
    "    def __init__(self, layers):\n",
    "        self.layers = []\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append(FullConnectedLayer(layers[i], layers[i+1],SigmoidActivator()))   # 创建全连接层，并添加到layers中\n",
    "\n",
    "\n",
    "    # 训练函数。labels: 样本标签矩阵。data_set: 输入样本矩阵。rate: 学习速率。epoch: 训练轮数\n",
    "    def train(self, labels, data_set, rate, epoch):\n",
    "        for i in range(epoch):\n",
    "            for d in range(len(data_set)):\n",
    "                # print(i,'次迭代，',d,'个样本')\n",
    "                oneobject = np.array(data_set[d]).reshape(-1,1)   #将输入对象和输出标签转化为列向量\n",
    "                onelabel = np.array(labels[d]).reshape(-1,1)\n",
    "                self.train_one_sample(onelabel,oneobject, rate)\n",
    "\n",
    "    # 内部函数，用一个样本训练网络\n",
    "    def train_one_sample(self, label, sample, rate):\n",
    "        # print('样本：\\n',sample)\n",
    "        self.predict(sample)  # 根据样本对象预测值\n",
    "        self.calc_gradient(label) # 计算梯度\n",
    "        self.update_weight(rate) # 更新权重\n",
    "\n",
    "    # 使用神经网络实现预测。sample: 输入样本\n",
    "    def predict(self, sample):\n",
    "        sample = sample.reshape(-1,1)   #将样本转换为列向量\n",
    "        output = sample  # 输入样本作为输入层的输出\n",
    "        for layer in self.layers:\n",
    "            # print('权值：',layer.W,layer.b)\n",
    "            layer.forward(output)  # 逐层向后计算预测值。因为每层都是线性回归\n",
    "            output = layer.output\n",
    "        # print('预测输出：', output)\n",
    "        return output\n",
    "\n",
    "         # 计算每个节点的误差。label为一个样本的输出向量，也就对应了最后一个所有输出节点输出的值\n",
    "    def calc_gradient(self, label):\n",
    "        # print('计算梯度：',self.layers[-1].activator.backward(self.layers[-1].output).shape)\n",
    "        delta = np.multiply(self.layers[-1].activator.backward(self.layers[-1].output),(label - self.layers[-1].output))  #计算输出误差\n",
    "        # print('输出误差：', delta.shape)\n",
    "        for layer in self.layers[::-1]:\n",
    "            layer.backward(delta)   # 逐层向前计算误差。计算神经网络层和输入层误差\n",
    "            delta = layer.delta\n",
    "            # print('当前层误差：', delta.shape)\n",
    "        return delta\n",
    "\n",
    "    # 更新每个连接权重\n",
    "    def update_weight(self, rate):\n",
    "        for layer in self.layers:  # 逐层更新权重\n",
    "            layer.update(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据返回结果计算所属类型\n",
    "def valye2type(vec):\n",
    "    return vec.argmax(axis=0)   # 获取概率最大的分类，由于vec是列向量，所以这里按列取最大的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用错误率来对网络进行评估\n",
    "def evaluate(network, test_data_set, test_labels):\n",
    "    error = 0\n",
    "    total = test_data_set.shape[0]\n",
    "    for i in range(total):\n",
    "        label = valye2type(test_labels[i])\n",
    "        predict = valye2type(network.predict(test_data_set[i]))\n",
    "        if label != predict:\n",
    "            error += 1\n",
    "    return float(error) / float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[-3.76464073 -3.68851559]]\n",
      "b: [[4.9756007]]\n",
      "W: [[ 5.41960439]\n",
      " [-5.42313583]]\n",
      "b: [[-2.04371404]\n",
      " [ 2.04526327]]\n",
      "分类： [0]\n",
      "分类： [0]\n",
      "分类： [0]\n",
      "分类： [1]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 使用神经网络实现and运算\n",
    "    data_set = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "    labels = np.array([[1,0],[1,0],[1,0],[0,1]])\n",
    "    # print(data_set)\n",
    "    # print(labels)\n",
    "    net = Network([2,1,2])  # 输入节点2个（偏量b会自动加上），神经元1个，输出节点2个。\n",
    "    net.train(labels, data_set, 2, 100)\n",
    "    for layer in net.layers:  # 网络层总不包含输出层\n",
    "        print('W:',layer.W)\n",
    "        print('b:',layer.b)\n",
    "\n",
    "    # 对结果进行预测\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            sample = np.array([[i, j]])\n",
    "            result = net.predict(sample)\n",
    "            type = valye2type(result)\n",
    "            print('分类：',type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始手写数字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本数据集的个数：6000\n",
      "测试数据集的个数：1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LuoD\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-06 12:13:31.022199 epoch 1 finished\n",
      "2018-08-06 12:13:31.158228 after epoch 1, error ratio is 0.217000\n",
      "2018-08-06 12:13:52.585273 epoch 2 finished\n",
      "2018-08-06 12:13:52.741301 after epoch 2, error ratio is 0.175000\n",
      "2018-08-06 12:14:12.202840 epoch 3 finished\n",
      "2018-08-06 12:14:12.322728 after epoch 3, error ratio is 0.150000\n",
      "2018-08-06 12:14:32.260771 epoch 4 finished\n",
      "2018-08-06 12:14:32.391648 after epoch 4, error ratio is 0.140000\n",
      "2018-08-06 12:14:51.442347 epoch 5 finished\n",
      "2018-08-06 12:14:51.579217 after epoch 5, error ratio is 0.142000\n",
      "2018-08-06 12:15:11.137910 epoch 6 finished\n",
      "2018-08-06 12:15:11.306921 after epoch 6, error ratio is 0.126000\n",
      "2018-08-06 12:15:30.989142 epoch 7 finished\n",
      "2018-08-06 12:15:31.148990 after epoch 7, error ratio is 0.128000\n",
      "2018-08-06 12:15:51.337736 epoch 8 finished\n",
      "2018-08-06 12:15:51.451630 after epoch 8, error ratio is 0.121000\n",
      "2018-08-06 12:16:11.617384 epoch 9 finished\n",
      "2018-08-06 12:16:11.755253 after epoch 9, error ratio is 0.116000\n",
      "2018-08-06 12:16:31.902776 epoch 10 finished\n",
      "2018-08-06 12:16:32.030654 after epoch 10, error ratio is 0.111000\n",
      "2018-08-06 12:16:52.476418 epoch 11 finished\n",
      "2018-08-06 12:16:52.599302 after epoch 11, error ratio is 0.117000\n",
      "2018-08-06 12:17:13.793173 epoch 12 finished\n",
      "2018-08-06 12:17:13.918061 after epoch 12, error ratio is 0.107000\n",
      "2018-08-06 12:17:33.750312 epoch 13 finished\n",
      "2018-08-06 12:17:33.875192 after epoch 13, error ratio is 0.107000\n",
      "2018-08-06 12:17:53.573556 epoch 14 finished\n",
      "2018-08-06 12:17:53.696446 after epoch 14, error ratio is 0.103000\n",
      "2018-08-06 12:18:14.745316 epoch 15 finished\n",
      "2018-08-06 12:18:14.865203 after epoch 15, error ratio is 0.106000\n",
      "2018-08-06 12:18:36.135488 epoch 16 finished\n",
      "2018-08-06 12:18:36.284349 after epoch 16, error ratio is 0.098000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2cfd941b400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_and_evaluate():\n",
    "    last_error_ratio = 1.0\n",
    "    epoch = 0\n",
    "    train_data_set, train_labels = get_training_data_set(6000,True)   # 加载训练样本数据集，和one-hot编码后的样本标签数据集\n",
    "    test_data_set, test_labels = get_test_data_set(1000,True)   # 加载测试特征数据集，和one-hot编码后的测试标签数据集\n",
    "    train_data_set=np.array(train_data_set)\n",
    "    train_labels=np.array(train_labels)\n",
    "    test_data_set=np.array(test_data_set)\n",
    "    test_labels=np.array(test_labels)\n",
    "\n",
    "\n",
    "    print('样本数据集的个数：%d' % len(train_data_set))\n",
    "    print('测试数据集的个数：%d' % len(test_data_set))\n",
    "    network = Network([784, 300, 10])  # 定义一个输入节点784+1，神经元300，输出10\n",
    "\n",
    "    error_ratios = []\n",
    "    while True:  # 迭代至准确率开始下降\n",
    "        epoch += 1 # 记录迭代次数\n",
    "        network.train(train_labels, train_data_set, 0.005, 1)  # 使用训练集进行训练。0.3为学习速率，1为迭代次数\n",
    "        print('%s epoch %d finished' % (datetime.datetime.now(), epoch))  # 打印时间和迭代次数\n",
    "        # if epoch  == 0:  # 每训练10次，就计算一次准确率\n",
    "        error_ratio = evaluate(network, test_data_set, test_labels)  # 计算准确率\n",
    "        error_ratios.append(error_ratio)\n",
    "        print('%s after epoch %d, error ratio is %f' % (datetime.datetime.now(), epoch, error_ratio))  # 打印输出错误率\n",
    "        if error_ratio < 0.1:  # 设置终止条件，正确率大于90%时停止\n",
    "            break\n",
    "    index=0\n",
    "    for layer in network.layers:\n",
    "        np.savetxt('MNIST—W'+str(index),layer.W)\n",
    "        np.savetxt('MNIST—b' + str(index), layer.b)\n",
    "        index+=1\n",
    "        # 把模型参数存储起来\n",
    "        # print(layer.W)\n",
    "        # print(layer.b)\n",
    "    plt.plot(list(range(len(error_ratios))), error_ratios)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_and_evaluate()   # 使用样本数据集进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
